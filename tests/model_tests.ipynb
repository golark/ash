{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21e384ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Loading local model: ../models/qwen2.5-coder-3b-instruct-q4_k_m.gguf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Local model loaded successfully in 2.06 seconds!\n",
      "ðŸ”¥ Warming up model...\n",
      "âœ… Model warmed up in 7.87 seconds!\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('..')\n",
    "import ash\n",
    "\n",
    "importlib.reload(ash)\n",
    "\n",
    "from ash.server import ASHModel\n",
    "m = ASHModel('../models/qwen2.5-coder-3b-instruct-q4_k_m.gguf')\n",
    "m.load()\n",
    "\n",
    "def exec_test_cases(test_cases):\n",
    "    results = []\n",
    "    total_points = 0\n",
    "\n",
    "    # Test each case\n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        query = test_case['query']\n",
    "        expected = test_case['expected']\n",
    "        points = test_case['points']\n",
    "\n",
    "        total_points += points\n",
    "\n",
    "        try:\n",
    "            # Start timer for this test case\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Call AI model\n",
    "            ai_response = m.generate_command(query)\n",
    "\n",
    "            # End timer and calculate duration\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "\n",
    "            # Simple comparison - check if expected command is in AI response\n",
    "            # This handles cases where AI might add arguments or variations\n",
    "            if isinstance(ai_response, str):\n",
    "                ai_response = ai_response.strip('\"')\n",
    "                ai_response = ai_response.strip('\\'')\n",
    "\n",
    "            # For each expected command, check if all its tokens (split by space) are present in the ai_response, regardless of order.\n",
    "            def command_tokens_match(expected_cmd, ai_cmd):\n",
    "                # Remove extra quotes and normalize whitespace\n",
    "                expected_tokens = expected_cmd.replace('\"', '').replace(\"'\", '').split()\n",
    "                ai_tokens = ai_cmd.replace('\"', '').replace(\"'\", '').split()\n",
    "                # All expected tokens must be present in ai_response tokens (order doesn't matter)\n",
    "                return all(token in ai_tokens for token in expected_tokens)\n",
    "\n",
    "            is_correct = any(command_tokens_match(str(e), ai_response) for e in expected)\n",
    "\n",
    "            results.append({\n",
    "                'query': query,\n",
    "                'ai_response': ai_response,\n",
    "                'pass/fail': 'PASS' if is_correct else 'FAIL',\n",
    "                'expected': expected,\n",
    "                'elapsed': round(duration, 3)\n",
    "            })\n",
    "\n",
    "            #print(f\"Test {i}: {query} | {expected} | {ai_response} - {duration:.3f}s - {'PASS' if is_correct else 'FAIL'}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— ERROR: {e}\")\n",
    "\n",
    "        # Small delay to avoid overwhelming the API\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b324e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average inference time: 2.314 seconds\n",
      "PASS percentage: 83.33%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>ai_response</th>\n",
       "      <th>pass/fail</th>\n",
       "      <th>expected</th>\n",
       "      <th>elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>install python3.12 using brew</td>\n",
       "      <td>brew install python@3.12</td>\n",
       "      <td>PASS</td>\n",
       "      <td>[brew install python3.12, brew install python@...</td>\n",
       "      <td>8.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>search curl using brew</td>\n",
       "      <td>brew search curl</td>\n",
       "      <td>PASS</td>\n",
       "      <td>[brew search, brew search package_name]</td>\n",
       "      <td>1.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>list installed packages for brew</td>\n",
       "      <td>brew list</td>\n",
       "      <td>PASS</td>\n",
       "      <td>[brew list, brew list --formula, brew list --c...</td>\n",
       "      <td>1.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>upgrade git using brew</td>\n",
       "      <td>brew upgrade git</td>\n",
       "      <td>PASS</td>\n",
       "      <td>[brew upgrade, brew upgrade package_name]</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tapped brew repositories</td>\n",
       "      <td>brew update</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>[brew tap, brew tap user/repo]</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uninstall git using brew</td>\n",
       "      <td>brew uninstall git</td>\n",
       "      <td>PASS</td>\n",
       "      <td>[brew uninstall git]</td>\n",
       "      <td>1.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              query               ai_response pass/fail  \\\n",
       "0     install python3.12 using brew  brew install python@3.12      PASS   \n",
       "1            search curl using brew          brew search curl      PASS   \n",
       "2  list installed packages for brew                 brew list      PASS   \n",
       "3            upgrade git using brew          brew upgrade git      PASS   \n",
       "4          tapped brew repositories               brew update      FAIL   \n",
       "5          uninstall git using brew        brew uninstall git      PASS   \n",
       "\n",
       "                                            expected  elapsed  \n",
       "0  [brew install python3.12, brew install python@...    8.976  \n",
       "1            [brew search, brew search package_name]    1.027  \n",
       "2  [brew list, brew list --formula, brew list --c...    1.079  \n",
       "3          [brew upgrade, brew upgrade package_name]    0.906  \n",
       "4                     [brew tap, brew tap user/repo]    0.799  \n",
       "5                               [brew uninstall git]    1.099  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_case = './brew.json'\n",
    "with open(f'test_data/{test_case}') as f:\n",
    "    test_cases = json.load(f)\n",
    "\n",
    "results = exec_test_cases(test_cases)\n",
    "\n",
    "avg_inference_time = results['elapsed'].mean()\n",
    "print(f\"\\nAverage inference time: {avg_inference_time:.3f} seconds\")\n",
    "pass_percentage = ((results['pass/fail'] == 'PASS').sum() / len(results)) * 100\n",
    "print(f\"PASS percentage: {pass_percentage:.2f}%\")\n",
    "display(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
